---
layout: post
title: "UTF-8 et encodage"
---

# Premièrement, c'est quoi l'encodage ?
L’encodage est une transformation de données compréhensibles comme une lettre, une couleur ou un son en données binaires (des 0 et des 1).
# UTF-8 est donc un encodage ?
Oui mais il transforme pas n'importe quelles données. L'encodage UTF-8 peut transformer tous les caractères définis dans Unicode (**UTF** signifie _Unicode Transformation Format_) comme l’emoji caca 💩.
# C'est quoi Unicode ?
Unicode n'est pas un encodage, c'est comme un **grand dictionnaire**, un **catalogue géant** où chaque caractère a un petit numéro de série appelé code point qui commence par U+ :
- `🙂` = **U+1F642**
- `é` = **U+00E9**
- Et même le “𓂀” (un œil égyptien random) a son code
# Pourquoi l'encodage est important ?
Ton éditeur de texte manipule les caractères Unicode en mémoire. Tant que tu n’as pas **sauvegardé ton fichier**, le caractère `🙂` reste une valeur abstraite : l’éditeur sait que c’est un caractère Unicode valide (U+1F642) et peut demander à la police d’afficher le bon dessin.

Mais dès qu’il faut **enregistrer le fichier sur le disque**, il faut transformer ce numéro en **suite d’octets**. Parce qu'un fichier c’est juste un gros tas de 0 et de 1. UTF-8 prend ton `🙂` et le transforme en : `F0 9F 99 82` pour pouvoir le stocker. Si tu ne précises rien, la plupart des éditeurs modernes choisissent de stocker en **UTF-8** par défaut.

Quand tu lis un fichier, tu peux choisir l'encodage à utiliser. Mais si ton fichier encodé en UTF-8 est lu en ISO-8859-1, le lecteur n'arrivera pas à recomposer les 20 bits à partir de `F0 9F 99 82` et il affichera � à la place de 🙂.
# Comment UTF-8 encode les caractères ?
UTF-8 utilise un principe simple :
- Plus le numéro (code point) est petit, moins on a besoin d’octets pour l'encoder
- Plus il est grand, plus on utilise d’octets pour l'encoder

Le code point du caractère `🙂`  est **U+1F642**. En binaire, il s'écrit donc `0001 1111 0110 0100 0010`. Mais ce ne sont pas directement ces 20 bits qui sont stockés. C'est bien `F0 9F 99 82`.

UTF-8 précise qu'il faudra stocker :
- 1 octet pour représenter les 128 premiers caractères (ASCII)
- 2 octets pour représenter les caractères qui font jusqu’à 11 bits
- 3 octets pour représenter les caractères qui font jusqu’à 16 bits
- 4 octets pour représenter les caractères qui font jusqu’à 21 bits (maximum de Unicode)

UTF-8 utilisera donc 4 octets pré-remplis pour stocker le caractère `🙂`:
- 1 octet d'en tête `11110xxx`. Le bit de poids fort est toujours égal à 1. Ensuite il y a autant de 1 que d'octets de suite (3) puis on ajoute des 0. Si UTF-8 devait utiliser 3 octets, l'octet d'en-tête serait `1110 xxxx`.
- 3 octets de suite `10xxxxxx 10xxxxxx 10xxxxxx`

Les `x` seront remplacés par les **bits du code point** (0001 1111 0110 0100 0010) de droite à gauche :
- l'octet 4 prend les bits 6 derniers bits du code point `10000010`= `82`
- l'octet 3 prend les 6 bits précédents `10011001`= `99`
- l'octet 2 prend les 6 bits précédents `10011111`= `9F`
- l'octet 1 prend les bits précédents restants `11110000`= `F0`

On retrouve bien `F0 9F 99 82` en hexadécimal ou `1111 0000 1001 1111 1001 1001 1000 0010` en binaire.
# Pourquoi ne pas stocker directement les 20 bits ?
Si on stocke les 20 bits, le lecteur qui va les lire ne saura pas les interpréter. `0001 1111 0110 0100 0010`peut être lu comme 2 caractères U+7D et U+242 = `}ɂ` (Lettre minuscule latine Coup de glotte).

C'est pour cela que l'on décrit la longueur totale de la séquence dans le premier octet. Pour distinguer le premier octet des octets suivants, on a décidé que tous les octets de suite commencent toujours par 10.