---
layout: post
title: "UTF-8 et encodage"
---

# PremiÃ¨rement, c'est quoi l'encodage ?
Lâ€™encodage est une transformation de donnÃ©es comprÃ©hensibles comme une lettre, une couleur ou un son en donnÃ©es binaires (des 0 et des 1).
# UTF-8 est donc un encodage ?
Oui mais il transforme pas n'importe quelles donnÃ©es. L'encodage UTF-8 peut transformer tous les caractÃ¨res dÃ©finis dans Unicode (**UTF**Â signifieÂ _Unicode Transformation Format_) comme lâ€™emoji caca ğŸ’©.
# C'est quoi Unicode ?
Unicode n'est pas un encodage, c'est comme un **grand dictionnaire**, un **catalogue gÃ©ant** oÃ¹ chaque caractÃ¨re a un petit numÃ©ro de sÃ©rie appelÃ© code point qui commence par U+ :
- `ğŸ™‚` = **U+1F642**
- `Ã©` = **U+00E9**
- Et mÃªme le â€œğ“‚€â€ (un Å“il Ã©gyptien random) a son code
# Pourquoi l'encodage est important ?
Ton Ã©diteur de texte manipule les caractÃ¨res Unicode en mÃ©moire. Tant que tu nâ€™as pas **sauvegardÃ© ton fichier**, le caractÃ¨re `ğŸ™‚` reste une valeur abstraite : lâ€™Ã©diteur sait que câ€™est un caractÃ¨re Unicode valide (U+1F642) et peut demander Ã  la police dâ€™afficher le bon dessin.

Mais dÃ¨s quâ€™il faut **enregistrer le fichier sur le disque**, il faut transformer ce numÃ©ro en **suite dâ€™octets**. Parce qu'un fichier câ€™est juste un gros tas de 0 et de 1. UTF-8 prend ton `ğŸ™‚` et le transforme en : `F0 9F 99 82` pour pouvoir le stocker. Si tu ne prÃ©cises rien, la plupart des Ã©diteurs modernes choisissent de stocker en **UTF-8** par dÃ©faut.

Quand tu lis un fichier, tu peux choisir l'encodage Ã  utiliser. Mais si ton fichier encodÃ© en UTF-8 est lu en ISO-8859-1, le lecteur n'arrivera pas Ã  recomposer les 20 bits Ã  partir de `F0 9F 99 82` et il affichera ï¿½ Ã  la place de ğŸ™‚.
# Comment UTF-8 encode les caractÃ¨res ?
UTF-8 utilise un principe simple :
- Plus le numÃ©ro (code point) est petit, moins on a besoin dâ€™octets pour l'encoder
- Plus il est grand, plus on utilise dâ€™octets pour l'encoder

Le code point du caractÃ¨re `ğŸ™‚`  est **U+1F642**. En binaire, il s'Ã©crit donc `0001 1111 0110 0100 0010`. Mais ce ne sont pas directement ces 20 bits qui sont stockÃ©s. C'est bien `F0 9F 99 82`.

UTF-8 prÃ©cise qu'il faudra stocker :
- 1 octet pour reprÃ©senter les 128 premiers caractÃ¨res (ASCII)
- 2 octets pour reprÃ©senter les caractÃ¨res qui font jusquâ€™Ã  11 bits
- 3 octets pour reprÃ©senter les caractÃ¨res qui font jusquâ€™Ã  16 bits
- 4 octets pour reprÃ©senter les caractÃ¨res qui font jusquâ€™Ã  21 bits (maximum de Unicode)

UTF-8 utilisera donc 4 octets prÃ©-remplis pour stocker le caractÃ¨re `ğŸ™‚`:
- 1 octet d'en tÃªte `11110xxx`. Le bit de poids fort est toujours Ã©gal Ã  1. Ensuite il y a autant de 1 que d'octets de suite (3) puis on ajoute des 0. Si UTF-8 devait utiliser 3 octets, l'octet d'en-tÃªte serait `1110 xxxx`.
- 3 octets de suite `10xxxxxx 10xxxxxx 10xxxxxx`

Les `x` seront remplacÃ©s par les **bits du code point** (0001 1111 0110 0100 0010) de droite Ã  gauche :
- l'octet 4 prend les bits 6 derniers bits du code point `10000010`= `82`
- l'octet 3 prend les 6 bits prÃ©cÃ©dents `10011001`= `99`
- l'octet 2 prend les 6 bits prÃ©cÃ©dents `10011111`= `9F`
- l'octet 1 prend les bits prÃ©cÃ©dents restants `11110000`= `F0`

On retrouve bien `F0 9F 99 82` en hexadÃ©cimal ou `1111 0000 1001 1111 1001 1001 1000 0010` en binaire.
# Pourquoi ne pas stocker directement les 20 bits ?
Si on stocke les 20 bits, le lecteur qui va les lire ne saura pas les interprÃ©ter. `0001 1111 0110 0100 0010`peut Ãªtre lu comme 2 caractÃ¨res U+7D et U+242 = `}É‚` (Lettre minuscule latine Coup de glotte).

C'est pour cela que l'on dÃ©crit la longueur totale de la sÃ©quence dans le premier octet. Pour distinguer le premier octet des octets suivants, on a dÃ©cidÃ© que tous les octets de suite commencent toujours par 10.